{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this script gets the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url too long if you get all counties at once, seems like they can't handle it\n",
    "# the url is an api that provides empower program data at the zip-code level\n",
    "# the api lets you query the database with a sql statement\n",
    "url = 'https://geohealth.hhs.gov/dataaccess/rest/services/HHS_emPOWER_REST_Service_Public/MapServer/0/query'\n",
    "# set up directories\n",
    "diry = 'data'\n",
    "sub_diry = 'zips'\n",
    "fn= 'zips_data.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk up counties in norcal. The api seems to be able to handle 10 counties at once\n",
    "counties0 =['Del Norte', \n",
    "    'Siskiyou',\n",
    "    'Modoc',\n",
    "    'Humboldt',\n",
    "    'Trinity',\n",
    "    'Shasta',\n",
    "    'Lassen',\n",
    "    'Tehama',\n",
    "    'Plumas',\n",
    "    'Mendocino']\n",
    "counties1 = [\n",
    "    'Lake',\n",
    "    'Glenn',\n",
    "    'Butte',\n",
    "    'Colusa',\n",
    "    'Sutter',\n",
    "    'Yuba',\n",
    "    'Sierra',\n",
    "    'Nevada',\n",
    "    'Placer',\n",
    "    'Yolo']\n",
    "counties2=[\n",
    "    'Sacramento',\n",
    "    'El Dorado',\n",
    "    'Amador',\n",
    "    'Alpine',\n",
    "    'Calaveras',\n",
    "    'San Joaquin',\n",
    "    'Stanislaus',\n",
    "    'Tuolomne',\n",
    "    'Mono',\n",
    "    'Mariposa']\n",
    "counties3 = [\n",
    "    'Merced' ,\n",
    "    'Contra Costa', \n",
    "    'Solano', \n",
    "    'Marin', \n",
    "    'Napa',\n",
    "    'Sonoma', \n",
    "    'San Mateo',\n",
    "    'Santa Clara', \n",
    "    'San Francisco', \n",
    "    'Alameda']\n",
    "counties4 = [\n",
    "    'Santa Cruz',\n",
    "    'Madera']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATE = 'CA' AND COUNTY IN ('Del Norte','Siskiyou','Modoc','Humboldt','Trinity','Shasta','Lassen','Tehama','Plumas','Mendocino')\n"
     ]
    }
   ],
   "source": [
    "# get features 0\n",
    "where0 = \"STATE = 'CA' AND COUNTY IN (\"\n",
    "where_end0 = \")\"\n",
    "for x in counties0:\n",
    "    where0 +=f\"\\'{x}\\',\"\n",
    "where0 = where0[:-1] + where_end0\n",
    "print(where0)\n",
    "params0 = {\"where\": where0,\n",
    "         \"f\": \"geojson\",\n",
    "         \"outFields\": \"STATE,Medicare_Benes,Power_Dependent_Devices_DME,Zip_Code,Zip_Code_Recode\"\n",
    "         }\n",
    "r0 = requests.get(url, params=params0)\n",
    "features0 = json.loads(r0.content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATE = 'CA' AND COUNTY IN ('Lake','Glenn','Butte','Colusa','Sutter','Yuba','Sierra','Nevada','Placer','Yolo')\n"
     ]
    }
   ],
   "source": [
    "# get features 1\n",
    "where1 = \"STATE = 'CA' AND COUNTY IN (\"\n",
    "where_end1 = \")\"\n",
    "for x in counties1:\n",
    "    where1 +=f\"\\'{x}\\',\"\n",
    "where1 = where1[:-1] + where_end1 # remove a trailing comma b/c sql and apend end\n",
    "# the code passes a 'where' statment in sql, should be like\n",
    "# STATE = 'CA' AND COUNTY IN ('<county 0>', '<county1>', ... '<county 10>')\n",
    "print(where1)  # should be valid sql\n",
    "params1 = {\"where\": where1, # here goes the where statement\n",
    "         \"f\": \"geojson\", # format you want data in\n",
    "         \"outFields\": \"STATE,Medicare_Benes,Power_Dependent_Devices_DME,Zip_Code,Zip_Code_Recode\"\n",
    "         } # outfields are the columns you want, like what goes after `SELECT` you get these along with geometry of feature\n",
    "r1 = requests.get(url, params=params1) # make the request\n",
    "features1 = json.loads(r1.content.decode('utf-8')) # a feature is a geographic object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features1['features']) # looking for 131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATE = 'CA' AND COUNTY IN ('Sacramento','El Dorado','Amador','Alpine','Calaveras','San Joaquin','Stanislaus','Tuolomne','Mono','Mariposa')\n",
      "179\n"
     ]
    }
   ],
   "source": [
    "where2 = \"STATE = 'CA' AND COUNTY IN (\"\n",
    "where_end2 = \")\"\n",
    "for x in counties2:\n",
    "    where2 +=f\"\\'{x}\\',\"\n",
    "where2 = where2[:-1] + where_end2\n",
    "print(where2) \n",
    "params2 = {\"where\": where2,\n",
    "         \"f\": \"geojson\",\n",
    "         \"outFields\": \"STATE,Medicare_Benes,Power_Dependent_Devices_DME,Zip_Code,Zip_Code_Recode\"\n",
    "         }\n",
    "r2 = requests.get(url, params=params2)\n",
    "features2 = json.loads(r2.content.decode('utf-8'))\n",
    "print(len(features2['features']) )# should be 179"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATE = 'CA' AND COUNTY IN ('Merced','Contra Costa','Solano','Marin','Napa','Sonoma','San Mateo','Santa Clara','San Francisco','Alameda')\n",
      "316\n"
     ]
    }
   ],
   "source": [
    "where3 = \"STATE = 'CA' AND COUNTY IN (\"\n",
    "where_end3 = \")\"\n",
    "for x in counties3:\n",
    "    where3 +=f\"\\'{x}\\',\"\n",
    "where3 = where3[:-1] + where_end3\n",
    "print(where3)\n",
    "params3 = {\"where\": where3,\n",
    "         \"f\": \"geojson\",\n",
    "         \"outFields\": \"STATE,Medicare_Benes,Power_Dependent_Devices_DME,Zip_Code,Zip_Code_Recode\"\n",
    "         }\n",
    "r3 = requests.get(url, params=params3)\n",
    "features3 = json.loads(r3.content.decode('utf-8'))\n",
    "print(len(features3['features']) ) # should be 316"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATE = 'CA' AND COUNTY IN ('Santa Cruz','Madera')\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "where4 = \"STATE = 'CA' AND COUNTY IN (\"\n",
    "where_end4 = \")\"\n",
    "for x in counties4:\n",
    "    where4 +=f\"\\'{x}\\',\"\n",
    "where4 = where4[:-1] + where_end4\n",
    "print(where4)\n",
    "params4 = {\"where\": where4,\n",
    "         \"f\": \"geojson\",\n",
    "         \"outFields\": \"STATE,Medicare_Benes,Power_Dependent_Devices_DME,Zip_Code,Zip_Code_Recode\"\n",
    "         }\n",
    "r4 = requests.get(url, params=params4)\n",
    "features4 = json.loads(r4.content.decode('utf-8'))\n",
    "print(len(features4['features']) ) # should be 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n",
      "131\n",
      "179\n",
      "316\n",
      "27\n",
      "823\n"
     ]
    }
   ],
   "source": [
    "# double check\n",
    "print(len(features0['features']) )\n",
    "print(len(features1['features']) )\n",
    "print(len(features2['features']) )\n",
    "print(len(features3['features']) )\n",
    "print(len(features4['features']) )\n",
    "print(len(features0['features'])  + len(features1['features']) + len(features2['features'])+len(features3['features']) + len(features4['features']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine features from all 5 chunks into one\n",
    "all_features = features0['features'] + features1['features'] + features2['features'] + features3['features'] + features4['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "823"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# want header etc to be valid, so grab it from first file\n",
    "all_feat_obj = copy.deepcopy(features0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n",
      "170\n"
     ]
    }
   ],
   "source": [
    "# should be 170, being sure it copied OK\n",
    "print(len(all_feat_obj['features']))\n",
    "print(len(features0['features']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now repalce 0th features with all features\n",
    "all_feat_obj['features'] = copy.deepcopy(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "823\n"
     ]
    }
   ],
   "source": [
    "# should be 823, be sure it copied ok. Now we have a valid geojson with right headers, etc.\n",
    "# but with the features from all the chunks of data we downloaded\n",
    "print(len(all_feat_obj['features']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the file\n",
    "with open(os.path.join(diry, sub_diry, fn), 'w') as f:\n",
    "    json.dump(all_feat_obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
